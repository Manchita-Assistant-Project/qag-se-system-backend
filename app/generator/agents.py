import os
import random
from typing import Callable
from langchain.tools import BaseTool
from langchain_openai import AzureChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_community.vectorstores import Chroma

import app.generator.config as config
import app.database.db_utils as db_utils
import app.generator.utils as utils

from dotenv import load_dotenv
os.environ["OPENAI_API_KEY"] = config.OPENAI_API_KEY
os.environ["AZURE_OPENAI_ENDPOINT"] = config.AZURE_OPENAI_ENDPOINT
os.environ["OPENAI_API_TYPE"] = config.OPENAI_API_TYPE
os.environ["OPENAI_API_VERSION"] = config.OPENAI_API_VERSION
os.environ["OPENAI_DEPLOYMENT_NAME"] = config.OPENAI_DEPLOYMENT_NAME
load_dotenv()

from app.graph.prompts import QANDA_PROMPT, EVALUATE_PROMPT, FEEDBACK_PROMPT, INTERACTION_PROMPT

embedding_function = db_utils.get_embedding_function()
db = Chroma(persist_directory=db_utils.CHROMA_PATH, embedding_function=embedding_function)


class QandAGenerationAgent(BaseTool):
    """
    It does not choose the questions, it only generates them.
    
    Defines a Q&A Agent that ONLY generates questions and answers based on a given context.
    It saves the generated questions and answers in a JSON file.
    
    Returns:
        str: The response generated by the agent.
    """
    name = "Question and Answer Generation Agent"
    description = "Generates questions and answers based on a given context."
    
    def _run(self, input_data: str):
        query = ""
        json_path = utils.JSON_PATH

        model = AzureChatOpenAI(
            deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
            temperature=0.2
        )

        results = db.similarity_search_with_score(query, k=5)
        
        context_text = "\n\n---\n\n".join([doc.page_content for doc, _score in results])

        prompt_template = ChatPromptTemplate.from_template(QANDA_PROMPT)
        prompt = prompt_template.format(context=context_text)

        response_text = model.invoke(prompt).content

        utils.update_json(json_path, response_text.split('\n\n'))
        return response_text
    

class QandAEvaluationAgent(BaseTool):
    """
    Si lo último que el Agente respondió fue una pregunta, entonces evalúa la respuesta.
    En caso contrario, no hace nada.
    
    Si piden saber los puntos actuales, el agente debe responder con la cantidad de puntos.
    """
    name = "Question and Answer Evaluation Agent"
    description = "Evaluates the answer to a question. It also responds to requests for current points."
    
    def _run(self, input_data: str):    
        json_path: str=utils.JSON_PATH
        data = utils.load_json(json_path)       

        question, answer = input_data.split("|||")

        model = AzureChatOpenAI(
            deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
            temperature=0.2
        )
        
        prompt_template = ChatPromptTemplate.from_template(EVALUATE_PROMPT)
        prompt = prompt_template.format(context=data, answer=answer, question=question)
        response_text = model.invoke(prompt).content

        return response_text + ' - ¿Quieres saber por qué?'


class InteractionAgent(BaseTool):
    """
    Responds when asked about an specific topic about the context.
    """
    name = "Interaction Agent"
    description = "Responds when asked about an specific topic about the context."
    
    def _run(self, query: str):       
        model = AzureChatOpenAI(
            deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
            temperature=0.5
        )
        results = db.similarity_search_with_score(query, k=5)
        
        context_text = "\n\n---\n\n".join([doc.page_content for doc, _score in results])
        prompt_template = ChatPromptTemplate.from_template(INTERACTION_PROMPT)
        prompt = prompt_template.format(context=context_text)
        
        response_text = model.invoke(prompt).content

        return response_text

class FeedbackAgent(BaseTool):
    """
    Responds when asked about feedback on an answer.
    """
    name = "Feedback Agent"
    description = "Responds when asked about feedback on an answer."
    
    def _run(self, input_data: str):
        question, answer = input_data.split("|||")
        
        model = AzureChatOpenAI(
            deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
            temperature=0.5
        )
        results = db.similarity_search_with_score(question, k=10)
        
        context_text = "\n\n---\n\n".join([doc.page_content for doc, _score in results])
        prompt_template = ChatPromptTemplate.from_template(FEEDBACK_PROMPT)
        prompt = prompt_template.format(context=context_text, question=question, answer=answer)
        
        response_text = model.invoke(prompt).content

        return response_text


class QandAChooserTool(BaseTool):
    """
    Defines a Q&A Chooser Tool that asks questions.

    Returns:
        str: The response generated by the agent.
    """
    name = 'Returns a question'
    description = 'If the users wants questions.'

    def _run(self, input_data: str):
        json_path: str=utils.JSON_PATH
        data = utils.load_json(json_path)       

        random_qanda = self._get_random_qanda_dict(data)

        return random_qanda

    def _get_questions(self, questions: list):
        return [each_qandas["question"] for each_qandas in questions[0]['questions']]
    
    def _get_random_question(self, questions: list):
        return random.choice(questions)
    
    def _get_random_qanda_dict(self, data: list):
        questions = self._get_questions(data)
        random_question = self._get_random_question(questions)
            
        return random_question
