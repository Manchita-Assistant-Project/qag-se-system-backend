import os
import random
from typing import Callable
from langchain.tools import BaseTool
from langchain_openai import AzureChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain_core.tools import tool
from langchain_community.vectorstores import Chroma

import app.generator.config as config
import app.database.db_utils as db_utils
import app.generator.utils as utils

from dotenv import load_dotenv
os.environ["OPENAI_API_KEY"] = config.OPENAI_API_KEY
os.environ["AZURE_OPENAI_ENDPOINT"] = config.AZURE_OPENAI_ENDPOINT
os.environ["OPENAI_API_TYPE"] = config.OPENAI_API_TYPE
os.environ["OPENAI_API_VERSION"] = config.OPENAI_API_VERSION
os.environ["OPENAI_DEPLOYMENT_NAME"] = config.OPENAI_DEPLOYMENT_NAME
load_dotenv()

from app.generator.prompts import QANDA_PROMPT, EVALUATE_PROMPT, FEEDBACK_PROMPT


embedding_function = db_utils.get_embedding_function()
db = Chroma(persist_directory=db_utils.CHROMA_PATH, embedding_function=embedding_function)


@tool('QandAGenerationAgent')
def QandAGenerationAgent():
    """
    Saves questions and answers to the JSON file.
    """
    query = ""
    json_path = utils.JSON_PATH

    model = AzureChatOpenAI(
        deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
        temperature=0.2
    )

    results = db.similarity_search_with_score(query, k=5)
    
    context_text = "\n\n---\n\n".join([doc.page_content for doc, _score in results])

    prompt_template = ChatPromptTemplate.from_template(QANDA_PROMPT)
    prompt = prompt_template.format(context=context_text)

    response_text = model.invoke(prompt).content

    utils.update_json(json_path, response_text.split('\n\n'))
    return response_text



@tool('QandAEvaluationAgent')
def QandAEvaluationAgent(input_data: str):
    """
    Evaluates the given answer to a question.
    """
    json_path: str=utils.JSON_PATH
    data = utils.load_json(json_path)       

    question, answer = input_data.split("|||")

    model = AzureChatOpenAI(
        deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
        temperature=0.2
    )
    
    prompt_template = ChatPromptTemplate.from_template(EVALUATE_PROMPT)
    prompt = prompt_template.format(context=data, answer=answer, question=question)
    response_text = model.invoke(prompt).content

    return response_text


@tool('InteractionAgent')
def InteractionAgent():
    """
    Responds when asked about an specific topic about the context.
    """
    # ======================================================================================================= #
    # TOCA CAMBIAR ESTE... TOCA QUE EL FEEDBACK SEA EN EVALUATE_AGENT Y ESTE SEA SOLO PARA INTERACCIÃ“N RAG... #
    # ======================================================================================================= #
    question, answer = input_data.split("|||")
    
    model = AzureChatOpenAI(
        deployment_name=os.environ["OPENAI_DEPLOYMENT_NAME"],
        temperature=0.2
    )
    results = db.similarity_search_with_score(question, k=5)
    
    context_text = "\n\n---\n\n".join([doc.page_content for doc, _score in results])
    prompt_template = ChatPromptTemplate.from_template(FEEDBACK_PROMPT)
    prompt = prompt_template.format(context=context_text, question=question, answer=answer)
    
    response_text = model.invoke(prompt).content
    print(f"INTERACTION_AGENT_RESPONSE: {response_text}")
    return response_text


class QandAChooserTool():
    """
    Defines a Q&A Chooser Tool that asks questions.

    Returns:
        str: The response generated by the agent.
    """
    name = 'Returns a question'
    description = 'If the users wants questions.'

    def _run(self):
        json_path: str=utils.JSON_PATH
        data = utils.load_json(json_path)       

        random_qanda = self._get_random_qanda_dict(data)

        return random_qanda

    def _get_questions(self, questions: list):
        return [each_qandas["question"] for each_qandas in questions[0]['questions']]
    
    def _get_random_question(self, questions: list):
        return random.choice(questions)
    
    def _get_random_qanda_dict(self, data: list):
        questions = self._get_questions(data)
        random_question = self._get_random_question(questions)
            
        return random_question

@tool('qanda_chooser')
def qanda_chooser():
    """
    It does not generate questions.
    Chooses a random question ONLY from the JSON file.
    """
    json_path: str=utils.JSON_PATH
    data = utils.load_json(json_path)
    questions = [each_qandas["question"] for each_qandas in data[0]['questions']]
    random_question = random.choice(questions)  

    return random_question


@tool('final_answer')
def final_answer(main_body: str):
    """
    Defines the final response to the user.
    """
    return ""
